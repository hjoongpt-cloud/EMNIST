{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a257d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] idx=1626 label=30 errors={'Median': 0.0028126349464996404, 'AdaptiveTh': 0.18940185825344155, 'Opening': 0.007214454737865688, 'CLAHE': 0.018098494208127418, 'NLM': 1.412330098576953e-06} saved visualization to denoise_comparison_outputs/sample_0_label_30.png\n",
      "[1] idx=15177 label=2 errors={'Median': 0.0024084536721603184, 'AdaptiveTh': 0.18653928156257088, 'Opening': 0.022668734705964585, 'CLAHE': 0.015944711142068028, 'NLM': 7.453955260327664e-07} saved visualization to denoise_comparison_outputs/sample_1_label_2.png\n",
      "[2] idx=2755 label=4 errors={'Median': 0.0037604846898375193, 'AdaptiveTh': 0.32814706228050483, 'Opening': 0.01426349009268466, 'CLAHE': 0.01635985754806527, 'NLM': 3.923134844544271e-08} saved visualization to denoise_comparison_outputs/sample_2_label_4.png\n",
      "[3] idx=14243 label=2 errors={'Median': 0.0026396049077055464, 'AdaptiveTh': 0.17394381245859813, 'Opening': 0.0050411931069168445, 'CLAHE': 0.015315479108874553, 'NLM': 1.0788628259811316e-05} saved visualization to denoise_comparison_outputs/sample_3_label_2.png\n",
      "[4] idx=7290 label=20 errors={'Median': 0.002441819924943045, 'AdaptiveTh': 0.2522425632463103, 'Opening': 0.008979395949838037, 'CLAHE': 0.0155859597385757, 'NLM': 7.846283163004992e-08} saved visualization to denoise_comparison_outputs/sample_4_label_20.png\n",
      "Saved summary to denoise_comparison_outputs/summary.json\n"
     ]
    }
   ],
   "source": [
    "# emnist_denoise_compare.py\n",
    "import os\n",
    "import random\n",
    "import json\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "from torchvision.datasets import EMNIST\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "def median_filter(img, k=3):\n",
    "    img_uint8 = (img * 255).astype(np.uint8)\n",
    "    return cv2.medianBlur(img_uint8, k) / 255.0\n",
    "\n",
    "def adaptive_threshold(img):\n",
    "    img_uint8 = (img * 255).astype(np.uint8)\n",
    "    th = cv2.adaptiveThreshold(img_uint8, 255,\n",
    "                               cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                               cv2.THRESH_BINARY, 11, 2)\n",
    "    return th / 255.0\n",
    "\n",
    "def morphological_opening(img, k=3):\n",
    "    img_uint8 = (img * 255).astype(np.uint8)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (k, k))\n",
    "    opened = cv2.morphologyEx(img_uint8, cv2.MORPH_OPEN, kernel)\n",
    "    return opened / 255.0\n",
    "\n",
    "def clahe_equalize(img):\n",
    "    img_uint8 = (img * 255).astype(np.uint8)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    return clahe.apply(img_uint8) / 255.0\n",
    "\n",
    "def non_local_means(img):\n",
    "    img_uint8 = (img * 255).astype(np.uint8)\n",
    "    return cv2.fastNlMeansDenoising(img_uint8, None, h=10, templateWindowSize=7, searchWindowSize=21) / 255.0\n",
    "\n",
    "def l2_error(a, b):\n",
    "    return np.mean((a - b)**2)\n",
    "\n",
    "def show_and_save_grid(imgs, titles, out_path, cmap='gray'):\n",
    "    n = len(imgs)\n",
    "    fig, axs = plt.subplots(1, n, figsize=(3 * n, 3))\n",
    "    if n == 1:\n",
    "        axs = [axs]\n",
    "    for ax, img, title in zip(axs, imgs, titles):\n",
    "        ax.imshow(img, cmap=cmap, vmin=0, vmax=1)\n",
    "        ax.set_title(title)\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_path, dpi=150)\n",
    "    plt.close(fig)\n",
    "\n",
    "def main():\n",
    "    set_seed(123)\n",
    "    out_dir = Path(\"denoise_comparison_outputs\")\n",
    "    out_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "    ds = EMNIST(root='data', split='balanced', train=False, download=True, transform=transform)\n",
    "\n",
    "    # pick N random samples\n",
    "    N = 5\n",
    "    idxs = np.random.choice(len(ds), size=N, replace=False)\n",
    "    summary = {}\n",
    "\n",
    "    for i, idx in enumerate(idxs):\n",
    "        img_tensor, label = ds[idx]\n",
    "        img = img_tensor.squeeze(0).numpy()  # [H,W], in [0,1]\n",
    "        # apply methods\n",
    "        med = median_filter(img)\n",
    "        th = adaptive_threshold(img)\n",
    "        opened = morphological_opening(img)\n",
    "        clahe = clahe_equalize(img)\n",
    "        nlm = non_local_means(img)\n",
    "\n",
    "        # compute errors\n",
    "        errors = {\n",
    "            'Median': l2_error(img, med),\n",
    "            'AdaptiveTh': l2_error(img, th),\n",
    "            'Opening': l2_error(img, opened),\n",
    "            'CLAHE': l2_error(img, clahe),\n",
    "            'NLM': l2_error(img, nlm),\n",
    "        }\n",
    "        summary[f'sample_{i}'] = {\n",
    "            'index': int(idx),\n",
    "            'label': int(label),\n",
    "            'errors': errors\n",
    "        }\n",
    "\n",
    "        # visualize\n",
    "        imgs = [img, med, th, opened, clahe, nlm]\n",
    "        titles = ['Original', 'Median', 'AdaptiveTh', 'Opening', 'CLAHE', 'Non-localMeans']\n",
    "        out_path = out_dir / f\"sample_{i}_label_{label}.png\"\n",
    "        show_and_save_grid(imgs, titles, out_path)\n",
    "        print(f\"[{i}] idx={idx} label={label} errors={errors} saved visualization to {out_path}\")\n",
    "\n",
    "    # dump summary\n",
    "    with open(out_dir / \"summary.json\", \"w\") as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "    print(f\"Saved summary to {out_dir / 'summary.json'}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
